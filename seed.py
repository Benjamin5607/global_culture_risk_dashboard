import os
import json
import requests
import time
import random
from datetime import datetime

API_KEY = os.environ.get("GROQ_API_KEY")

def get_current_date():
    return datetime.now().strftime("%Y-%m-%d")

# ==========================================
# [í•µì‹¬] ì–¼ë°˜ ë”•ì…”ë„ˆë¦¬ ë°ì´í„° í¬ë¡¤ë§ í•¨ìˆ˜
# ==========================================
def fetch_urban_data(term):
    try:
        # ì–¼ë°˜ ë”•ì…”ë„ˆë¦¬ ë¬´ë£Œ API í˜¸ì¶œ
        url = f"https://api.urbandictionary.com/v0/define?term={term}"
        response = requests.get(url, timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            items = data.get('list', [])
            
            if not items:
                return None # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ

            # ì¢‹ì•„ìš”(thumbs_up)ê°€ ê°€ì¥ ë§ì€ ì •ì˜ 1ë“± ì„ íƒ
            best_def = sorted(items, key=lambda x: x.get('thumbs_up', 0), reverse=True)[0]
            
            # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (300ì)
            definition = best_def.get('definition', '').replace('[', '').replace(']', '')
            if len(definition) > 300: definition = definition[:300] + "..."
            
            return definition
    except Exception as e:
        print(f"   âš ï¸ Urban Dict Error for '{term}': {e}")
    
    return None

# ==========================================
# ë©”ì¸ ê³µì¥ ì½”ë“œ
# ==========================================
def generate_hybrid_data():
    print("ğŸ­ Hybrid Factory: AI Search + Urban Dictionary Definitions...")

    if not API_KEY:
        print("âŒ Error: GROQ_API_KEY not found.")
        return

    try:
        with open("data.json", "r", encoding="utf-8") as f:
            current_data = json.load(f)
    except:
        current_data = []

    existing_terms = {item['term'].lower() for item in current_data}
    print(f"ğŸ“‚ Loaded {len(current_data)} existing items.")

    # ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ (ë‹¨ì–´ ìˆ˜ì§‘ìš©)
    prompts = []
    target_countries = ["USA", "UK", "Canada", "Australia"]
    
    # AIì—ê²ŒëŠ” "ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸"ë§Œ ë‹¬ë¼ê³  ìš”ì²­í•©ë‹ˆë‹¤. (ëœ»ì€ ìš°ë¦¬ê°€ ì°¾ì„ ê±°ë‹ˆê¹Œ)
    for country in target_countries:
        prompts.append(f"Most viral Gen Z slang words in {country} (2024-2025)")
        prompts.append(f"Controversial political dog whistles in {country}")
        prompts.append(f"TikTok trends and acronyms in {country}")

    random.shuffle(prompts)

    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}

    max_batches = 10
    for i, topic in enumerate(prompts[:max_batches]):
        if len(current_data) >= 500: break
        
        print(f"\nğŸ”„ [{i+1}/{max_batches}] AI: '{topic}' ë‹¨ì–´ ìˆ˜ì§‘ ì¤‘...")

        # í”„ë¡¬í”„íŠ¸: AIì•¼, ëœ»ì€ í•„ìš” ì—†ê³  'ë‹¨ì–´'ë‘ 'ì¹´í…Œê³ ë¦¬'ë§Œ ì¤˜.
        system_prompt = f"""
        List 8 viral terms related to "{topic}".
        Only output JSON.
        Schema:
        - term: string
        - category: string (Short hashtag style)
        - country: list of strings
        - group: 'language'
        - risk_level: 'Low' | 'Medium' | 'High'
        - trend_score: Integer (50-99)
        """

        payload = {
            "model": "llama-3.1-8b-instant",
            "messages": [
                {"role": "system", "content": "Output JSON only."},
                {"role": "user", "content": system_prompt}
            ],
            "response_format": {"type": "json_object"}
        }

        try:
            # 1. AIê°€ ë‹¨ì–´ ë¬¼ì–´ì˜´
            response = requests.post(url, headers=headers, json=payload)
            if response.status_code == 200:
                content = response.json()['choices'][0]['message']['content']
                ai_items = json.loads(content).get('items', [])
                
                added_count = 0
                for item in ai_items:
                    term = item['term'].strip()
                    
                    if term.lower() not in existing_terms:
                        print(f"   ğŸ” '{term}' -> Urban Dictionary ê²€ìƒ‰ ì¤‘...", end="")
                        
                        # 2. ì–¼ë°˜ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì§„ì§œ ëœ» ê°€ì ¸ì˜¤ê¸°
                        urban_def = fetch_urban_data(term)
                        
                        # ë°ì´í„° ì¡°ë¦½
                        item['term'] = term
                        item['image_url'] = "null" # ìŠ¬ë­ì€ ì´ë¯¸ì§€ ë¶ˆí•„ìš”
                        item['status'] = 'Active'
                        item['first_detected'] = get_current_date()
                        item['last_updated'] = get_current_date()
                        
                        # ëœ» ì±„ì›Œë„£ê¸° (ì–¼ë°˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ê±° ì“°ê³ , ì—†ìœ¼ë©´ AIê°€ ì¤€ê±° ì“°ê±°ë‚˜ 'No data')
                        real_def = urban_def if urban_def else "Definition provided by AI analysis."
                        
                        # ì–¸ì–´ë³„ ì»¨í…ìŠ¤íŠ¸ (í•œêµ­ì–´ëŠ” ë²ˆì—­ì´ ì—†ìœ¼ë¯€ë¡œ ì˜ì–´ ëœ»ì„ ê·¸ëŒ€ë¡œ ë„£ê±°ë‚˜ ê°„ë‹¨íˆ í‘œì‹œ)
                        item['context'] = {
                            "en": real_def,
                            "ko": f"(Urban Dict): {real_def}" if urban_def else "ë°ì´í„° ìˆ˜ì§‘ ì¤‘...",
                            "ja": real_def
                        }

                        current_data.append(item)
                        existing_terms.add(term.lower())
                        added_count += 1
                        print(" ì™„ë£Œ âœ…")
                        
                        # API ê³¼ë¶€í•˜ ë°©ì§€ (ì‚´ì§ ì‰¼)
                        time.sleep(0.5)
                
                print(f"   âœ¨ ë°°ì¹˜ ì™„ë£Œ: {added_count}ê°œ ì €ì¥ë¨.")
            
            else:
                print(f"   âŒ AI Error: {response.text}")

        except Exception as e:
            print(f"   âš ï¸ Error: {e}")

        time.sleep(1) # AI API íœ´ì‹

    # ì €ì¥
    print(f"\nğŸ’¾ Saving {len(current_data)} items to data.json...")
    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(current_data, f, indent=4, ensure_ascii=False)

if __name__ == "__main__":
    generate_hybrid_data()
